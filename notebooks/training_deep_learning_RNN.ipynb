{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing function \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>hops</th>\n",
       "      <th>special_characters_exists_subject</th>\n",
       "      <th>number_of_words_subject</th>\n",
       "      <th>number_of_capitalized_words_subject</th>\n",
       "      <th>number_of_capitalized_characters_subject</th>\n",
       "      <th>number_of_digits_subject</th>\n",
       "      <th>number_of_characters_subject</th>\n",
       "      <th>number_of_spaces_subject</th>\n",
       "      <th>number_of_special_characters_subject</th>\n",
       "      <th>number_of_single_Quotes_subject</th>\n",
       "      <th>number_of_semiColon_subject</th>\n",
       "      <th>ratio_of_uppercase/lowercase_words</th>\n",
       "      <th>Total_number_of_upperCase</th>\n",
       "      <th>Max_word_length_in_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62389</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62391</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62392</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62393</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2222222222222222</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62394 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label hops special_characters_exists_subject number_of_words_subject  \\\n",
       "0         1    3                                 0                       4   \n",
       "1         0    2                                 0                       3   \n",
       "2         0    9                                 1                       6   \n",
       "3         1    1                                 0                       3   \n",
       "4         0    6                                 0                       2   \n",
       "...     ...  ...                               ...                     ...   \n",
       "62389     0    4                                 0                       2   \n",
       "62390     0    1                                 1                       4   \n",
       "62391     1    1                                 0                       4   \n",
       "62392     0    4                                 0                       2   \n",
       "62393     0    4                                 1                      11   \n",
       "\n",
       "      number_of_capitalized_words_subject  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       3   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "...                                   ...   \n",
       "62389                                   0   \n",
       "62390                                   0   \n",
       "62391                                   1   \n",
       "62392                                   0   \n",
       "62393                                   2   \n",
       "\n",
       "      number_of_capitalized_characters_subject number_of_digits_subject  \\\n",
       "0                                            0                        0   \n",
       "1                                            0                        0   \n",
       "2                                            7                        0   \n",
       "3                                            2                        0   \n",
       "4                                            1                        0   \n",
       "...                                        ...                      ...   \n",
       "62389                                        1                        0   \n",
       "62390                                        1                        7   \n",
       "62391                                        7                        0   \n",
       "62392                                        1                        0   \n",
       "62393                                        5                        1   \n",
       "\n",
       "      number_of_characters_subject number_of_spaces_subject  \\\n",
       "0                               19                        4   \n",
       "1                                9                        2   \n",
       "2                               15                        6   \n",
       "3                               12                        2   \n",
       "4                                2                        1   \n",
       "...                            ...                      ...   \n",
       "62389                            2                        1   \n",
       "62390                            7                        3   \n",
       "62391                           26                        4   \n",
       "62392                            2                        1   \n",
       "62393                           30                       11   \n",
       "\n",
       "      number_of_special_characters_subject number_of_single_Quotes_subject  \\\n",
       "0                                        0                             0.0   \n",
       "1                                        0                             0.0   \n",
       "2                                        4                             0.0   \n",
       "3                                        0                             0.0   \n",
       "4                                        0                             0.0   \n",
       "...                                    ...                             ...   \n",
       "62389                                    0                             0.0   \n",
       "62390                                    1                             0.0   \n",
       "62391                                    0                             0.0   \n",
       "62392                                    0                             0.0   \n",
       "62393                                    2                             0.0   \n",
       "\n",
       "      number_of_semiColon_subject ratio_of_uppercase/lowercase_words  \\\n",
       "0                               0                                0.0   \n",
       "1                               0                                0.0   \n",
       "2                               0                                1.0   \n",
       "3                               0                                0.0   \n",
       "4                               0                                0.0   \n",
       "...                           ...                                ...   \n",
       "62389                           0                                0.0   \n",
       "62390                           0                                0.0   \n",
       "62391                           0                 0.3333333333333333   \n",
       "62392                           0                                0.0   \n",
       "62393                           0                 0.2222222222222222   \n",
       "\n",
       "      Total_number_of_upperCase Max_word_length_in_subject  \n",
       "0                             0                          9  \n",
       "1                             0                          6  \n",
       "2                             3                          8  \n",
       "3                             0                          7  \n",
       "4                             0                          2  \n",
       "...                         ...                        ...  \n",
       "62389                         0                          2  \n",
       "62390                         0                          6  \n",
       "62391                         1                         11  \n",
       "62392                         0                          2  \n",
       "62393                         2                          7  \n",
       "\n",
       "[62394 rows x 15 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_df = pd.read_csv(\"data_with_features.csv\", dtype='unicode')\n",
    "rnn_df = rnn_df.drop(['Return-Path','Message-ID','From','Reply-To','To','Submitting Host','Subject','Date','X-Mailer','MIME-Version','Content-Type','X-Priority','X-MSMail-Priority','Status','Content-Length','Content-Transfer-Encoding','Lines'], axis = 1)\n",
    "rnn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data for testing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(rnn_df) * 0.5)\n",
    "train_data = rnn_df.iloc[:-test_size,:].copy()\n",
    "test_data = rnn_df.iloc[-test_size:,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_data.drop('Label',axis=1).copy()\n",
    "label_train = train_data[['Label']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert pandas dataframes to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "feature_scaler.fit(features_train)\n",
    "scaled_feature_train = feature_scaler.transform(features_train)\n",
    "\n",
    "label_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "label_scaler.fit(label_train)\n",
    "scaled_label_train = label_scaler.transform(label_train)\n",
    "\n",
    "scaled_label_train = scaled_label_train.reshape(-1)\n",
    "\n",
    "\n",
    "scaled_label_train = np.insert(scaled_label_train, 0, 0)\n",
    "scaled_label_train = np.delete(scaled_label_train, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge feature training and label training numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 25, 14)\n"
     ]
    }
   ],
   "source": [
    "n_input = 25 \n",
    "n_features= features_train.shape[1]\n",
    "b_size = 32\n",
    "generator = TimeseriesGenerator(scaled_feature_train, scaled_label_train, length=n_input, batch_size=b_size)\n",
    "\n",
    "print(generator[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 25, 128)           73216     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,961\n",
      "Trainable params: 208,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape=(n_input, n_features), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "975/975 [==============================] - 93s 95ms/step - loss: 0.4209 - acc: 0.8045\n",
      "Epoch 2/100\n",
      "975/975 [==============================] - 91s 93ms/step - loss: 0.4059 - acc: 0.8114\n",
      "Epoch 3/100\n",
      "975/975 [==============================] - 81s 83ms/step - loss: 0.3950 - acc: 0.8215\n",
      "Epoch 4/100\n",
      "975/975 [==============================] - 201s 206ms/step - loss: 0.3873 - acc: 0.8267\n",
      "Epoch 5/100\n",
      "975/975 [==============================] - 82s 84ms/step - loss: 0.3767 - acc: 0.8344\n",
      "Epoch 6/100\n",
      "975/975 [==============================] - 80s 82ms/step - loss: 0.3660 - acc: 0.8405\n",
      "Epoch 7/100\n",
      "975/975 [==============================] - 81s 83ms/step - loss: 0.3594 - acc: 0.8462\n",
      "Epoch 8/100\n",
      "975/975 [==============================] - 80s 82ms/step - loss: 0.3537 - acc: 0.8503\n",
      "Epoch 9/100\n",
      "975/975 [==============================] - 107s 109ms/step - loss: 0.3479 - acc: 0.8545\n",
      "Epoch 10/100\n",
      "975/975 [==============================] - 97s 99ms/step - loss: 0.3416 - acc: 0.8581\n",
      "Epoch 11/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.3406 - acc: 0.8604\n",
      "Epoch 12/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.3308 - acc: 0.8643\n",
      "Epoch 13/100\n",
      "975/975 [==============================] - 87s 90ms/step - loss: 0.3284 - acc: 0.8659\n",
      "Epoch 14/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.3243 - acc: 0.8676\n",
      "Epoch 15/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.3219 - acc: 0.8678\n",
      "Epoch 16/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.3178 - acc: 0.8724\n",
      "Epoch 17/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.3145 - acc: 0.8740\n",
      "Epoch 18/100\n",
      "975/975 [==============================] - 86s 89ms/step - loss: 0.3101 - acc: 0.8777\n",
      "Epoch 19/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.3079 - acc: 0.8772\n",
      "Epoch 20/100\n",
      "975/975 [==============================] - 90s 92ms/step - loss: 0.3020 - acc: 0.8793\n",
      "Epoch 21/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.3004 - acc: 0.8804\n",
      "Epoch 22/100\n",
      "975/975 [==============================] - 87s 90ms/step - loss: 0.3006 - acc: 0.8800\n",
      "Epoch 23/100\n",
      "975/975 [==============================] - 90s 92ms/step - loss: 0.2949 - acc: 0.8849\n",
      "Epoch 24/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2955 - acc: 0.8831\n",
      "Epoch 25/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2907 - acc: 0.8882\n",
      "Epoch 26/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2889 - acc: 0.8889\n",
      "Epoch 27/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.2843 - acc: 0.8889\n",
      "Epoch 28/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2823 - acc: 0.8897\n",
      "Epoch 29/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.2781 - acc: 0.8919\n",
      "Epoch 30/100\n",
      "975/975 [==============================] - 89s 91ms/step - loss: 0.2780 - acc: 0.8928\n",
      "Epoch 31/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2764 - acc: 0.8935\n",
      "Epoch 32/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2734 - acc: 0.8942\n",
      "Epoch 33/100\n",
      "975/975 [==============================] - 87s 90ms/step - loss: 0.2741 - acc: 0.8939\n",
      "Epoch 34/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2715 - acc: 0.8946\n",
      "Epoch 35/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2668 - acc: 0.8979\n",
      "Epoch 36/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2649 - acc: 0.8974\n",
      "Epoch 37/100\n",
      "975/975 [==============================] - 88s 91ms/step - loss: 0.2633 - acc: 0.8984\n",
      "Epoch 38/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2626 - acc: 0.8978\n",
      "Epoch 39/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2602 - acc: 0.8999\n",
      "Epoch 40/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2574 - acc: 0.9025\n",
      "Epoch 41/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2568 - acc: 0.9017\n",
      "Epoch 42/100\n",
      "975/975 [==============================] - 86s 89ms/step - loss: 0.2533 - acc: 0.9021\n",
      "Epoch 43/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2545 - acc: 0.9024\n",
      "Epoch 44/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.2499 - acc: 0.9028\n",
      "Epoch 45/100\n",
      "975/975 [==============================] - 89s 91ms/step - loss: 0.2459 - acc: 0.9049\n",
      "Epoch 46/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2458 - acc: 0.9065\n",
      "Epoch 47/100\n",
      "975/975 [==============================] - 88s 90ms/step - loss: 0.2453 - acc: 0.9046\n",
      "Epoch 48/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2432 - acc: 0.9062\n",
      "Epoch 49/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2393 - acc: 0.9074\n",
      "Epoch 50/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2407 - acc: 0.9077\n",
      "Epoch 51/100\n",
      "975/975 [==============================] - 89s 91ms/step - loss: 0.2383 - acc: 0.9083\n",
      "Epoch 52/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2344 - acc: 0.9105\n",
      "Epoch 53/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2336 - acc: 0.9107\n",
      "Epoch 54/100\n",
      "975/975 [==============================] - 89s 92ms/step - loss: 0.2292 - acc: 0.9120\n",
      "Epoch 55/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2295 - acc: 0.9112\n",
      "Epoch 56/100\n",
      "975/975 [==============================] - 87s 89ms/step - loss: 0.2330 - acc: 0.9119\n",
      "Epoch 57/100\n",
      "975/975 [==============================] - 87s 90ms/step - loss: 0.2258 - acc: 0.9138\n",
      "Epoch 58/100\n",
      "975/975 [==============================] - 89s 91ms/step - loss: 0.2229 - acc: 0.9149\n",
      "Epoch 59/100\n",
      "975/975 [==============================] - 148s 152ms/step - loss: 0.2267 - acc: 0.9131\n",
      "Epoch 60/100\n",
      "975/975 [==============================] - 166s 170ms/step - loss: 0.2237 - acc: 0.9146\n",
      "Epoch 61/100\n",
      "975/975 [==============================] - 163s 167ms/step - loss: 0.2224 - acc: 0.9147\n",
      "Epoch 62/100\n",
      "975/975 [==============================] - 162s 166ms/step - loss: 0.2194 - acc: 0.9162\n",
      "Epoch 63/100\n",
      "975/975 [==============================] - 32162s 33s/step - loss: 0.2189 - acc: 0.9159\n",
      "Epoch 64/100\n",
      "123/975 [==>...........................] - ETA: 6:33 - loss: 0.2105 - acc: 0.9202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-99b739c21a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot losses per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split testing data into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = test_data.drop('Label',axis=1).copy()\n",
    "label_test = test_data[['Label']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Test Data to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 25, 14)\n"
     ]
    }
   ],
   "source": [
    "scaled_test_data = feature_scaler.transform(features_test)\n",
    "test_generator = TimeseriesGenerator(scaled_test_data, np.zeros(len(test_data)), length=n_input, batch_size=b_size)\n",
    "print(test_generator[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31167</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31170</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31172 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       true  pred\n",
       "0         0     1\n",
       "1         0     0\n",
       "2         0     0\n",
       "3         1     1\n",
       "4         1     1\n",
       "...     ...   ...\n",
       "31167     0     1\n",
       "31168     0     0\n",
       "31169     1     0\n",
       "31170     0     1\n",
       "31171     0     0\n",
       "\n",
       "[31172 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scaled = model.predict(test_generator)\n",
    "pred = label_scaler.inverse_transform(pred_scaled)\n",
    "results = pd.DataFrame({'true':test_data['Label'].values[n_input:],'pred':pred.ravel()})\n",
    "results.loc[results.pred >= 0.5, 'pred'] = 1\n",
    "results.loc[results.pred < 0.5, 'pred'] = 0\n",
    "results['true'] = results['true'].astype(int)\n",
    "results['pred'] = results['pred'].astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "Precision: 0.63\n",
      "Recall: 0.65\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(results['true'], results['pred'])\n",
    "precision = precision_score(results['true'], results['pred'])\n",
    "recall = recall_score(results['true'], results['pred'])\n",
    "print('Accuracy: {:.2f}\\nPrecision: {:.2f}\\nRecall: {:.2f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
